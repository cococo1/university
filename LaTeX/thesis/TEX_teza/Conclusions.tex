\section*{Conclusions}
\phantomsection


	NAO is an excellent robot for research, but he still cannot be used for any practical task. His battery drains fast (in one-two hours), and the speed of his movements is low. There are also quite high errors in movement precisions. The initial goal was not reached due to the combination of two factors: static analysis of the current state and errors of precision committed by robot while walking. The analysis is static because NAO computes his position relative to objects using just one image. One solution to this problem might be real-time or close to real-time image processing.

	This project can serve as a detailed analysis of humanoid's capabilities mostly concerned to interaction with objects and humans. K-means clustering with features extracted just from images provides a good way to sort a set of objects. The image of an object contains enough information to represent it. Elbow method is effective in deciding the number of clusters. K-means together with Elbow method solved the core of the problem. Clustering itself in a generic form might be used by robots to learn the world around them, since it is unsupervised learning and the knowledge attained is a result of data which robot takes from its sensors but not from preprogrammed instructions inserted by humans. The implementation of object detection proved to be very effective and independent of background. It is still affected by conditions of illumination. 

	During this project a method of distance determination from image was proposed. The implementation of the program shows that it is possible to compute with high accuracy the distance to an object using just an image and additional knowledge about camera's specifications and its position in space. Knowing the height of the camera and the height angle it is possible to compute the forward distance. The height angle is formed by the line which is the orthogonal projection of the camera center on the ground and the line formed by camera center and the point with camera \( x \) coordinate and object center \( y \) coordinate. Knowing the camera projection distance and the lateral angle it is possible to compute the lateral distance. The camera projection distance is the distance bounded by camera on one end and point of intersection of camera's vector projection with the ground. The camera projection distance can be computed having forward distance. The lateral angle is the angle formed by the camera projection line and object center. Having the forward and lateral distances it is possible to compute both the distance towards the object and the position relative to camera of the object.   

	For object detection a set of OpenCV methods were implemented. Background subtraction and shadow removal were used. The OpenCV method of finding the contours of the objects was implemented. Object detection and object clustering modules can be easily reused in other projects. Distance computation module might be useful for a wide range of tasks performed by NAO. The model of human-robotic interaction implemented here is a generic one and can be easily extended for very different practices. Computer Vision and image processing is still a challenging task. It requires much processing power and complex algorithms to be truly successful and independent of circumstances.

	A vast amount of time was spent experimenting with NAO movement precision and grasping capabilities. It was shown that this specific instance of the robot has one motor of motion biased, resulting in a significant error. The project once again emphasized the issue of grasping with three fingers. While this thesis was being finished, Aldebaran Robotics released the next generation humanoid -- Pepper. Pepper tackles this issue and has five fingers. Experiments were also concerned about NAO's capabilities to detect obstacles and pick an object from the ground without falling down. The program is able to deal with almost any object, any number of groups and any background. This work itself might be interesting and useful in future robotics research and improvements, both concerned about NAO and other robots as well.  

	This project also presents a successful example of interaction between three components from different branches of IT: robotic functionality, image processing and machine learning. Since the main task was not practically achieved, there is much future work to be done. The biggest problem unsolved is the incapacity of the robot to walk exactly the right distance. The problem comes from the biased motors used during walking. But it could be tackled by recomputing the distances and errors from time to time. That way, even if the robot would have imprecise movements, it would compensate his errors until the result is good enough. This requires the processing of the image with objects more than once. It also requires to keep track which object is which in the new, closer image (that is, object recognition besides object detection which is done at the moment). Since the image needs to be processed at least a few times in some short interval, may be even once a second, the program needs to be run locally, on robot. 


	The network image retrieval during remote execution would not permit to respect such short intervals, since to get an image from robot to the PC remotely takes a couple of seconds (for the best resolution image). But running the system on the robot could lead to possible delays during clustering, since the robot's processor is weaker than the one from the PC and the clustering is a computationally expensive operation. This means that an important factor in the future work would be to balance the processing expenses versus the frequency of distance recalculation. Besides that, more detailed features of the objects might be added, increasing the robot's profficiency in sorting even similar objects. Another thing which was not tested is the diversity of the clustering algorithms. Just one of them was implemented. Others might be compared with that as well. Another problem is the grasping itself, which is dependent of the mechanical form of the NAO's hand. Finally, when the robot would be good at sorting things locally, the project can be upgraded to make NAO perform more difficult tasks, like moving the objects around the room. 



\clearpage